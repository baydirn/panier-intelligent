# Guide: Comment trouver les vraies API de circulaires

## R√©sultat des tests initiaux

‚ùå **Tous les endpoints sugg√©r√©s par ChatGPT ont √©chou√©**:
- Metro: Connexion refus√©e
- Walmart: "You do not have access to this url"
- Flyerify: 404 Not Found
- IGA/Sobeys: √Ä tester

## ‚úÖ M√©thode recommand√©e: Reverse Engineering

### √âtape 1: Inspecter le site web r√©el

1. **Ouvrir le site de la circulaire** dans Chrome/Edge:
   - Metro: https://www.metro.ca/circulaire
   - IGA: https://www.iga.net/fr/circulaire
   - Walmart: https://www.walmart.ca/fr/flyer
   - Maxi: https://www.maxi.ca/circulaire

2. **Ouvrir DevTools** (F12)

3. **Onglet Network** ‚Üí Filtrer par "Fetch/XHR"

4. **Recharger la page** et chercher les requ√™tes JSON qui chargent les produits

5. **Copier l'URL r√©elle** et les headers n√©cessaires

### √âtape 2: Exemple concret - IGA

```powershell
# 1. Aller sur https://www.iga.net/fr/circulaire
# 2. F12 ‚Üí Network ‚Üí XHR
# 3. Chercher une requ√™te qui retourne du JSON avec les produits
# 4. Clic droit ‚Üí Copy ‚Üí Copy as PowerShell

# Exemple typique (√† adapter selon ce que tu trouves):
$headers = @{
    "Accept" = "application/json"
    "Referer" = "https://www.iga.net/fr/circulaire"
    "User-Agent" = "Mozilla/5.0..."
}
Invoke-RestMethod -Uri "URL_TROUVEE_DANS_NETWORK" -Headers $headers
```

## Alternative: Scraping HTML direct

Si aucune API n'est accessible, on scrappe le HTML:

### Test IGA HTML:
```powershell
$html = Invoke-WebRequest -Uri "https://www.iga.net/fr/circulaire" -UseBasicParsing
$html.Content | Out-File iga-page.html
# Analyser iga-page.html pour trouver les s√©lecteurs CSS
```

### Test Metro HTML:
```powershell
$html = Invoke-WebRequest -Uri "https://www.metro.ca/circulaire" -UseBasicParsing
$html.Content | Out-File metro-page.html
```

## üéØ Plan r√©vis√©

### Phase 1: Investigation (maintenant)
1. Visiter chaque site web manuellement
2. Inspecter Network pour trouver les vraies API
3. Documenter les endpoints r√©els

### Phase 2: Impl√©mentation
- **Si API trouv√©e**: Scraper JSON (facile, fiable)
- **Si pas d'API**: Scraper HTML avec Cheerio (plus fragile)

### Phase 3: Fallback
- Garder le dataset manuel enrichi actuel (`api/scrapers/flipp.js`)
- Mise √† jour hebdomadaire manuelle si n√©cessaire

## üìù Template pour documenter les vraies API

Cr√©er un fichier `REAL_ENDPOINTS.md` avec:

```markdown
## IGA
- URL: [√† compl√©ter apr√®s inspection]
- Method: GET
- Headers requis: [√† compl√©ter]
- Params: ?store_id=XXX&postal_code=XXX
- Response: { ... }

## Metro
- URL: [√† compl√©ter]
- ...
```

## Prochaines √©tapes

1. **Toi**: Inspecter 1-2 sites manuellement (IGA + Metro recommand√©s)
2. **Copilot**: Impl√©menter les scrapers bas√©s sur tes d√©couvertes
3. **Ensemble**: Tester et affiner

---

**Note importante**: Les vraies API sont souvent:
- Non document√©es publiquement
- Prot√©g√©es par des tokens/cookies de session
- Changeantes (structure peut varier)
- Soumises √† rate limiting

C'est pourquoi un **dataset manuel enrichi + OCR pour upload communautaire** reste une excellente approche long-terme.
